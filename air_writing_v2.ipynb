{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntitkyn7xDj4",
        "outputId": "f6b52c19-ff23-4d93-8ff2-fa4587cd0b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/trnhhunhthnhkhang/vi-air-writing?dataset_version_number=8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 555M/555M [00:29<00:00, 19.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/trnhhunhthnhkhang/vi-air-writing/versions/8\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"trnhhunhthnhkhang/vi-air-writing\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  # Changed from StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "eG2z8V4jZ8lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AirWritingTrainer:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.model = None\n",
        "        self.labels = {}\n",
        "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        self.max_length = 100\n",
        "        os.makedirs(\"training_samples\", exist_ok=True)\n",
        "\n",
        "    def load_data(self, folder_types=[\"1_gram\", \"2_grams\", \"3_grams\", \"n_grams\"], max_samples_per_label=1000):\n",
        "        \"\"\"\n",
        "        Load data from different n-gram directories\n",
        "        \"\"\"\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "\n",
        "        for folder_type in folder_types:\n",
        "            folder_path = os.path.join(self.data_path, folder_type)\n",
        "\n",
        "            if not os.path.exists(folder_path):\n",
        "                print(f\"Warning: Path {folder_path} does not exist, skipping.\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                labels = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
        "            except Exception as e:\n",
        "                print(f\"Error accessing {folder_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            for label in labels:\n",
        "                label_path = os.path.join(folder_path, label)\n",
        "\n",
        "                try:\n",
        "                    label_files = [f for f in os.listdir(label_path) if f.endswith('.csv')]\n",
        "                    if max_samples_per_label > 0:\n",
        "                        label_files = label_files[:max_samples_per_label]\n",
        "                except Exception as e:\n",
        "                    print(f\"Error accessing {label_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                for file in label_files:\n",
        "                    file_path = os.path.join(label_path, file)\n",
        "                    try:\n",
        "                        df = pd.read_csv(file_path)\n",
        "\n",
        "                        if 'x' in df.columns and 'y' in df.columns:\n",
        "                            coords = df[['x', 'y']].values\n",
        "                        else:\n",
        "                            coords = df.iloc[:, 0:2].values\n",
        "\n",
        "                        if len(coords) > 0:\n",
        "                            coords = self.normalize_coordinates(coords)\n",
        "                            all_data.append(coords)\n",
        "                            all_labels.append(label)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "        print(f\"Loaded {len(all_data)} samples across {len(set(all_labels))} unique labels\")\n",
        "\n",
        "        unique_labels = sorted(set(all_labels))\n",
        "        self.labels = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "        return all_data, all_labels\n",
        "\n",
        "    def normalize_coordinates(self, coords):\n",
        "        \"\"\"Normalize coordinates to [0,1] range while preserving aspect ratio\"\"\"\n",
        "        min_x, min_y = np.min(coords, axis=0)\n",
        "        max_x, max_y = np.max(coords, axis=0)\n",
        "\n",
        "        # Calculate range, avoiding division by zero\n",
        "        width = max(max_x - min_x, 1e-5)\n",
        "        height = max(max_y - min_y, 1e-5)\n",
        "\n",
        "        # Normalize to [0,1] range\n",
        "        normalized = coords.copy()\n",
        "        normalized[:, 0] = (coords[:, 0] - min_x) / width\n",
        "        normalized[:, 1] = (coords[:, 1] - min_y) / height\n",
        "\n",
        "        return normalized\n",
        "\n",
        "    def preprocess_data(self, data, labels):\n",
        "        \"\"\"\n",
        "        Preprocess the air writing coordinate data\n",
        "        \"\"\"\n",
        "        # Check if we have data to process\n",
        "        if not data or len(data) == 0:\n",
        "            raise ValueError(\"No data to preprocess\")\n",
        "\n",
        "        # Pad or truncate sequences to fixed length\n",
        "        padded_data = []\n",
        "        for seq in data:\n",
        "            if len(seq) > self.max_length:\n",
        "                indices = np.linspace(0, len(seq)-1, self.max_length).astype(int)\n",
        "                seq = seq[indices]\n",
        "            else:\n",
        "                # Pad shorter sequences\n",
        "                seq = np.pad(seq, ((0, self.max_length - len(seq)), (0, 0)), mode='constant')\n",
        "            padded_data.append(seq)\n",
        "\n",
        "        padded_data = np.array(padded_data)\n",
        "\n",
        "        # Add additional features\n",
        "        processed_data = self.add_dynamic_features(padded_data)\n",
        "\n",
        "        # Fit and transform the data using the scaler\n",
        "        original_shape = processed_data.shape\n",
        "        processed_data = self.scaler.fit_transform(\n",
        "            processed_data.reshape(-1, processed_data.shape[-1])\n",
        "        ).reshape(original_shape)\n",
        "\n",
        "        # Save some sample data for debugging\n",
        "        self.save_sample_data(processed_data, labels)\n",
        "\n",
        "        # Convert labels to categorical\n",
        "        label_indices = [self.labels[label] for label in labels]\n",
        "        categorical_labels = to_categorical(label_indices, num_classes=len(self.labels))\n",
        "\n",
        "        return processed_data, categorical_labels\n",
        "\n",
        "    def add_dynamic_features(self, data):\n",
        "        \"\"\"\n",
        "        Add velocity features to improve model performance\n",
        "        \"\"\"\n",
        "        # Original data shape: (samples, time_steps, 2)\n",
        "        samples, time_steps, coords = data.shape\n",
        "\n",
        "        # Initialize the new feature array (coordinates + velocity)\n",
        "        new_features = np.zeros((samples, time_steps, coords * 2))\n",
        "\n",
        "        for i in range(samples):\n",
        "            # Copy original coordinates\n",
        "            new_features[i, :, 0:coords] = data[i]\n",
        "\n",
        "            # Calculate velocity (difference between consecutive points)\n",
        "            velocity = np.zeros((time_steps, coords))\n",
        "            # Only compute velocity for points 1 to end (point 0 has no velocity)\n",
        "            velocity[1:] = np.diff(data[i], axis=0)\n",
        "            new_features[i, :, coords:2*coords] = velocity\n",
        "\n",
        "        return new_features\n",
        "\n",
        "    def save_sample_data(self, processed_data, labels, num_samples=5):\n",
        "        \"\"\"Save sample processed data for debugging\"\"\"\n",
        "        if len(processed_data) == 0:\n",
        "            return\n",
        "\n",
        "        indices = np.random.choice(len(processed_data),\n",
        "                                  min(num_samples, len(processed_data)),\n",
        "                                  replace=False)\n",
        "\n",
        "        for i, idx in enumerate(indices):\n",
        "            sample = processed_data[idx]\n",
        "            label = labels[idx]\n",
        "\n",
        "            # Save visualization\n",
        "            plt.figure(figsize=(12, 6))\n",
        "\n",
        "            # Plot coordinates\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.title(f\"Sample {i}: {label}\")\n",
        "            plt.plot(sample[:, 0], sample[:, 1], 'b-')\n",
        "            plt.scatter(sample[0, 0], sample[0, 1], c='g', s=50, label='Start')\n",
        "\n",
        "            # Find last non-zero point\n",
        "            non_zero = np.where((sample[:, 0] != 0) | (sample[:, 1] != 0))[0]\n",
        "            if len(non_zero) > 0:\n",
        "                last_idx = non_zero[-1]\n",
        "                plt.scatter(sample[last_idx, 0], sample[last_idx, 1],\n",
        "                           c='r', s=50, label='End')\n",
        "\n",
        "            plt.legend()\n",
        "\n",
        "            # Plot features\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.title(\"Feature Values\")\n",
        "            plt.plot(range(len(sample)), sample[:, 0], 'r-', label='x')\n",
        "            plt.plot(range(len(sample)), sample[:, 1], 'g-', label='y')\n",
        "            plt.plot(range(len(sample)), sample[:, 2], 'b-', label='vx')\n",
        "            plt.plot(range(len(sample)), sample[:, 3], 'y-', label='vy')\n",
        "            plt.legend()\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"training_samples/sample_{i}_{label}.png\")\n",
        "            plt.close()\n",
        "\n",
        "            # Save raw data\n",
        "            np.save(f\"training_samples/sample_{i}_{label}.npy\", sample)\n",
        "\n",
        "        print(f\"Saved {len(indices)} sample visualizations to training_samples/\")\n",
        "\n",
        "    def create_model(self, input_shape, num_classes):\n",
        "        \"\"\"\n",
        "        Create an improved model for Vietnamese air writing recognition\n",
        "        \"\"\"\n",
        "        model = Sequential([\n",
        "            Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "\n",
        "            Bidirectional(GRU(128, return_sequences=True)),\n",
        "            Dropout(0.3),\n",
        "            Bidirectional(GRU(64, return_sequences=False)),\n",
        "            Dropout(0.3),\n",
        "\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_and_save_model(self, test_size=0.2, random_state=42, batch_size=32, epochs=100):\n",
        "        \"\"\"\n",
        "        Complete training pipeline with detailed logging\n",
        "        \"\"\"\n",
        "        print(\"Starting the training process...\")\n",
        "\n",
        "        # Load data\n",
        "        data, labels = self.load_data()\n",
        "        if not data:\n",
        "            raise ValueError(\"No data was loaded. Check your dataset path.\")\n",
        "\n",
        "        # Preprocess data\n",
        "        print(f\"Preprocessing {len(data)} samples...\")\n",
        "        X, y = self.preprocess_data(data, labels)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "        print(f\"Number of classes: {y.shape[1]}\")\n",
        "\n",
        "        # Prepare model input shape\n",
        "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "        num_classes = y_train.shape[1]\n",
        "\n",
        "        # Create and compile model\n",
        "        self.model = self.create_model(input_shape, num_classes)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        # Callbacks for better training\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Training with progress updates\n",
        "        print(\"\\nTraining model...\")\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[early_stopping, reduce_lr],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        print(\"\\nEvaluating model...\")\n",
        "        test_loss, test_accuracy = self.model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "        # Save model and metadata\n",
        "        self.save_model()\n",
        "\n",
        "        # Plot training history\n",
        "        self._plot_training_history(history)\n",
        "\n",
        "        # Save preprocessing info\n",
        "        self.save_preprocessing_info()\n",
        "\n",
        "        return test_accuracy\n",
        "\n",
        "    def save_preprocessing_info(self):\n",
        "        \"\"\"Save preprocessing details for reference\"\"\"\n",
        "        info = {\n",
        "            'max_length': self.max_length,\n",
        "            'scaler_type': type(self.scaler).__name__,\n",
        "            'feature_range': self.scaler.feature_range if hasattr(self.scaler, 'feature_range') else None,\n",
        "            'normalization': 'per_sample',\n",
        "            'features': ['x', 'y', 'vx', 'vy']\n",
        "        }\n",
        "\n",
        "        with open('preprocessing_info.txt', 'w') as f:\n",
        "            for key, value in info.items():\n",
        "                f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "        print(\"Saved preprocessing info to preprocessing_info.txt\")\n",
        "\n",
        "    def save_model(self, model_path='air_writing_model.h5', metadata_path='model_metadata.joblib'):\n",
        "        \"\"\"\n",
        "        Save trained model and labels\n",
        "        \"\"\"\n",
        "        if self.model:\n",
        "            # Save model\n",
        "            self.model.save(model_path)\n",
        "\n",
        "            # Save metadata\n",
        "            joblib.dump({\n",
        "                'labels': self.labels,\n",
        "                'scaler': self.scaler,\n",
        "                'max_length': self.max_length,\n",
        "                'scaler_params': {\n",
        "                    'type': type(self.scaler).__name__,\n",
        "                    'feature_range': self.scaler.feature_range if hasattr(self.scaler, 'feature_range') else None\n",
        "                }\n",
        "            }, metadata_path)\n",
        "\n",
        "            print(f\"Model saved to {model_path}\")\n",
        "            print(f\"Metadata saved to {metadata_path}\")\n",
        "\n",
        "            # Print out label mapping\n",
        "            print(\"\\nLabel Mapping:\")\n",
        "            for label, index in self.labels.items():\n",
        "                print(f\"{label}: {index}\")\n",
        "        else:\n",
        "            print(\"No model to save. Train a model first.\")\n",
        "\n",
        "    def _plot_training_history(self, history):\n",
        "        \"\"\"\n",
        "        Plot and save training metrics\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Accuracy plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "\n",
        "        # Loss plot\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history.png')\n",
        "        print(\"Training history plot saved to 'training_history.png'\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "P7nuYs8ZMuOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = path + \"/VNI_airwriting\"\n",
        "trainer = AirWritingTrainer(data_path)\n",
        "trainer.train_and_save_model(\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    batch_size=32,\n",
        "    epochs=100\n",
        ")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TmKiYbWLMwEn",
        "outputId": "61d271e7-6edf-43cf-b192-ab4dfdad8278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the training process...\n",
            "Loaded 22760 samples across 660 unique labels\n",
            "Preprocessing 22760 samples...\n",
            "Saved 5 sample visualizations to training_samples/\n",
            "Training set: 18208 samples\n",
            "Testing set: 4552 samples\n",
            "Number of classes: 660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m148,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m123,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m660\u001b[0m)                 │          \u001b[38;5;34m85,140\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">148,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">85,140</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m375,124\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">375,124</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m375,124\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">375,124</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "Training model...\n",
            "Epoch 1/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.0304 - loss: 5.6262 - val_accuracy: 0.3214 - val_loss: 2.9013 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.2809 - loss: 2.9188 - val_accuracy: 0.6322 - val_loss: 1.4194 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.5070 - loss: 1.7679 - val_accuracy: 0.7821 - val_loss: 0.8113 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6457 - loss: 1.2109 - val_accuracy: 0.8363 - val_loss: 0.5914 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7204 - loss: 0.9145 - val_accuracy: 0.8937 - val_loss: 0.3763 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7785 - loss: 0.7044 - val_accuracy: 0.9091 - val_loss: 0.3148 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8139 - loss: 0.5768 - val_accuracy: 0.9279 - val_loss: 0.2429 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8517 - loss: 0.4715 - val_accuracy: 0.9391 - val_loss: 0.1962 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.3997 - val_accuracy: 0.9427 - val_loss: 0.1729 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8835 - loss: 0.3613 - val_accuracy: 0.9631 - val_loss: 0.1337 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9010 - loss: 0.3058 - val_accuracy: 0.9620 - val_loss: 0.1218 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9099 - loss: 0.2851 - val_accuracy: 0.9690 - val_loss: 0.1035 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9207 - loss: 0.2451 - val_accuracy: 0.9662 - val_loss: 0.1128 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9257 - loss: 0.2239 - val_accuracy: 0.9714 - val_loss: 0.0978 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9252 - loss: 0.2170 - val_accuracy: 0.9750 - val_loss: 0.0841 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9299 - loss: 0.2162 - val_accuracy: 0.9769 - val_loss: 0.0799 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9430 - loss: 0.1765 - val_accuracy: 0.9802 - val_loss: 0.0699 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9480 - loss: 0.1595 - val_accuracy: 0.9809 - val_loss: 0.0714 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9491 - loss: 0.1553 - val_accuracy: 0.9793 - val_loss: 0.0736 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9512 - loss: 0.1449 - val_accuracy: 0.9780 - val_loss: 0.0736 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9542 - loss: 0.1449 - val_accuracy: 0.9824 - val_loss: 0.0626 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9581 - loss: 0.1269 - val_accuracy: 0.9833 - val_loss: 0.0643 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9586 - loss: 0.1259 - val_accuracy: 0.9842 - val_loss: 0.0596 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9585 - loss: 0.1237 - val_accuracy: 0.9826 - val_loss: 0.0680 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9631 - loss: 0.1101 - val_accuracy: 0.9855 - val_loss: 0.0594 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9626 - loss: 0.1161 - val_accuracy: 0.9851 - val_loss: 0.0531 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9634 - loss: 0.1135 - val_accuracy: 0.9870 - val_loss: 0.0517 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9643 - loss: 0.1073 - val_accuracy: 0.9897 - val_loss: 0.0446 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9655 - loss: 0.1016 - val_accuracy: 0.9855 - val_loss: 0.0507 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9654 - loss: 0.1036 - val_accuracy: 0.9875 - val_loss: 0.0483 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9695 - loss: 0.0969 - val_accuracy: 0.9895 - val_loss: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9698 - loss: 0.0945 - val_accuracy: 0.9901 - val_loss: 0.0428 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9673 - loss: 0.1011 - val_accuracy: 0.9851 - val_loss: 0.0616 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9682 - loss: 0.0991 - val_accuracy: 0.9884 - val_loss: 0.0466 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9741 - loss: 0.0812 - val_accuracy: 0.9897 - val_loss: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9716 - loss: 0.0890 - val_accuracy: 0.9903 - val_loss: 0.0408 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.0824 - val_accuracy: 0.9888 - val_loss: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9723 - loss: 0.0920 - val_accuracy: 0.9881 - val_loss: 0.0506 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9708 - loss: 0.0847 - val_accuracy: 0.9917 - val_loss: 0.0383 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9725 - loss: 0.0796 - val_accuracy: 0.9908 - val_loss: 0.0405 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9754 - loss: 0.0778 - val_accuracy: 0.9897 - val_loss: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9723 - loss: 0.0878 - val_accuracy: 0.9928 - val_loss: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9763 - loss: 0.0747 - val_accuracy: 0.9886 - val_loss: 0.0479 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9722 - loss: 0.0859 - val_accuracy: 0.9934 - val_loss: 0.0245 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9720 - loss: 0.0880 - val_accuracy: 0.9917 - val_loss: 0.0460 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9783 - loss: 0.0669 - val_accuracy: 0.9925 - val_loss: 0.0364 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9791 - loss: 0.0650 - val_accuracy: 0.9919 - val_loss: 0.0390 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9763 - loss: 0.0757 - val_accuracy: 0.9930 - val_loss: 0.0349 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9790 - loss: 0.0647\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9790 - loss: 0.0647 - val_accuracy: 0.9932 - val_loss: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9831 - loss: 0.0509 - val_accuracy: 0.9932 - val_loss: 0.0310 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9902 - loss: 0.0310 - val_accuracy: 0.9952 - val_loss: 0.0262 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9903 - loss: 0.0291 - val_accuracy: 0.9947 - val_loss: 0.0304 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9925 - loss: 0.0218 - val_accuracy: 0.9936 - val_loss: 0.0275 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m567/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0316\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0316 - val_accuracy: 0.9943 - val_loss: 0.0274 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9913 - loss: 0.0257 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9941 - loss: 0.0189 - val_accuracy: 0.9958 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0192 - val_accuracy: 0.9963 - val_loss: 0.0180 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9934 - loss: 0.0190 - val_accuracy: 0.9956 - val_loss: 0.0223 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.9954 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9933 - loss: 0.0171 - val_accuracy: 0.9954 - val_loss: 0.0207 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9948 - loss: 0.0153 - val_accuracy: 0.9954 - val_loss: 0.0241 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m568/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9949 - loss: 0.0176\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.9949 - val_loss: 0.0206 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0151 - val_accuracy: 0.9956 - val_loss: 0.0203 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9957 - loss: 0.0132 - val_accuracy: 0.9960 - val_loss: 0.0189 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9954 - loss: 0.0138 - val_accuracy: 0.9963 - val_loss: 0.0209 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9954 - val_loss: 0.0206 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m567/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 0.0123\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9965 - loss: 0.0123 - val_accuracy: 0.9958 - val_loss: 0.0190 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.9965 - val_loss: 0.0187 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9958 - loss: 0.0132 - val_accuracy: 0.9963 - val_loss: 0.0193 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9963 - val_loss: 0.0181 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9963 - val_loss: 0.0191 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m566/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9966 - loss: 0.0105\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9960 - val_loss: 0.0185 - learning_rate: 6.2500e-05\n",
            "Epoch 72: early stopping\n",
            "Restoring model weights from the end of the best epoch: 57.\n",
            "\n",
            "Evaluating model...\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.63%\n",
            "Model saved to air_writing_model.h5\n",
            "Metadata saved to model_metadata.joblib\n",
            "\n",
            "Label Mapping:\n",
            "anh_w: 0\n",
            "ba_w: 1\n",
            "bao giờ_w: 2\n",
            "bia_w: 3\n",
            "biển rộng_w: 4\n",
            "biển xanh rộng_w: 5\n",
            "biển xanh sóng vỗ_w: 6\n",
            "biển đêm lung linh_w: 7\n",
            "biển_w: 8\n",
            "buồn bã_w: 9\n",
            "buồn_w: 10\n",
            "buổi chiều yên ả_w: 11\n",
            "buổi sáng se lạnh_w: 12\n",
            "buổi sáng trong lành_w: 13\n",
            "buổi sáng xanh_w: 14\n",
            "buổi tối mát mẻ_w: 15\n",
            "bà_w: 16\n",
            "bài tập_w: 17\n",
            "bàn ghế_w: 18\n",
            "bàn phím_w: 19\n",
            "bàn ăn_w: 20\n",
            "bàn_w: 21\n",
            "bán_w: 22\n",
            "bánh mì_w: 23\n",
            "bánh_w: 24\n",
            "bãi biển rộng mênh mông_w: 25\n",
            "bãi cát trắng tinh_w: 26\n",
            "bãi cỏ xanh mướt_w: 27\n",
            "bé_w: 28\n",
            "béo_w: 29\n",
            "bên cạnh_w: 30\n",
            "bí_w: 31\n",
            "bò_w: 32\n",
            "bóng cây mát_w: 33\n",
            "bóng_w: 34\n",
            "bông hoa đẹp xinh_w: 35\n",
            "bún_w: 36\n",
            "bút chì_w: 37\n",
            "bút_w: 38\n",
            "bơ_w: 39\n",
            "bưởi_w: 40\n",
            "bạn bè_w: 41\n",
            "bản chất_w: 42\n",
            "bản tin_w: 43\n",
            "bảo vệ_w: 44\n",
            "bảy_w: 45\n",
            "bất tiện_w: 46\n",
            "bầu trời trong xanh_w: 47\n",
            "bầu trời trong_w: 48\n",
            "bầu trời đầy sao_w: 49\n",
            "bầu_w: 50\n",
            "bẩn_w: 51\n",
            "bằng chứng_w: 52\n",
            "bằng cách nào_w: 53\n",
            "bền_w: 54\n",
            "bệnh viện_w: 55\n",
            "bốn_w: 56\n",
            "bộ lạc_w: 57\n",
            "bộ máy_w: 58\n",
            "bộ môn_w: 59\n",
            "bộ nhớ_w: 60\n",
            "bộ phim_w: 61\n",
            "bộ phận_w: 62\n",
            "bộ sách_w: 63\n",
            "bộ sưu tập_w: 64\n",
            "bộ đồ_w: 65\n",
            "bộ_w: 66\n",
            "bởi vì_w: 67\n",
            "bởi_w: 68\n",
            "cam_w: 69\n",
            "canh_w: 70\n",
            "cao cấp_w: 71\n",
            "cao_w: 72\n",
            "cay_w: 73\n",
            "cha_w: 74\n",
            "chai_w: 75\n",
            "chim bay cao_w: 76\n",
            "chim_w: 77\n",
            "chiên_w: 78\n",
            "chiếc lá bay_w: 79\n",
            "chiếc xe chạy nhanh_w: 80\n",
            "chiếc_w: 81\n",
            "cho_w: 82\n",
            "chua_w: 83\n",
            "chuyên nghiệp_w: 84\n",
            "chuối_w: 85\n",
            "chà_w: 86\n",
            "cháo_w: 87\n",
            "chát_w: 88\n",
            "chè_w: 89\n",
            "chín_w: 90\n",
            "chó_w: 91\n",
            "chơi_w: 92\n",
            "chạy_w: 93\n",
            "chả_w: 94\n",
            "chất lượng_w: 95\n",
            "chậm chạp_w: 96\n",
            "chậm_w: 97\n",
            "chắc chắn_w: 98\n",
            "chẳng hạn_w: 99\n",
            "chặt chẽ_w: 100\n",
            "chỉ_w: 101\n",
            "chị_w: 102\n",
            "con bướm tung tăng_w: 103\n",
            "con chim bay cao_w: 104\n",
            "con chó chạy quanh_w: 105\n",
            "con ngựa phi_w: 106\n",
            "con suối nhỏ bé_w: 107\n",
            "con suối nhỏ_w: 108\n",
            "con tim ấm áp_w: 109\n",
            "con đường nhỏ xinh_w: 110\n",
            "con đường nhỏ_w: 111\n",
            "con đường_w: 112\n",
            "con_w: 113\n",
            "cuộc họp_w: 114\n",
            "cà phê_w: 115\n",
            "cà_w: 116\n",
            "cá_w: 117\n",
            "cái_w: 118\n",
            "cánh chim bay_w: 119\n",
            "cánh đồng hoa dại_w: 120\n",
            "cánh đồng hoa khoe sắc_w: 121\n",
            "cánh đồng lúa xanh_w: 122\n",
            "cánh đồng vàng_w: 123\n",
            "câu chuyện đời thường_w: 124\n",
            "cây cối_w: 125\n",
            "cây cổ thụ rợp bóng_w: 126\n",
            "cây xanh bên đường_w: 127\n",
            "cây xanh_w: 128\n",
            "cây_w: 129\n",
            "có lẽ_w: 130\n",
            "có thể_w: 131\n",
            "có vẻ_w: 132\n",
            "có_w: 133\n",
            "công nghệ_w: 134\n",
            "công ty_w: 135\n",
            "công viên_w: 136\n",
            "công việc_w: 137\n",
            "căn phòng ấm áp_w: 138\n",
            "cũ_w: 139\n",
            "cũng vậy_w: 140\n",
            "cũng_w: 141\n",
            "cơ hội_w: 142\n",
            "cơm_w: 143\n",
            "cơn bão quét qua_w: 144\n",
            "cơn gió lạnh_w: 145\n",
            "cơn gió thổi mạnh_w: 146\n",
            "cơn mưa chợt đến_w: 147\n",
            "cơn mưa nhẹ nhàng_w: 148\n",
            "cơn mưa đêm vắng_w: 149\n",
            "cười_w: 150\n",
            "cải_w: 151\n",
            "cảm ơn_w: 152\n",
            "cần_w: 153\n",
            "cầu thang_w: 154\n",
            "cẩn thận_w: 155\n",
            "cặp_w: 156\n",
            "cộng đồng_w: 157\n",
            "cụ thể_w: 158\n",
            "của_w: 159\n",
            "cứng_w: 160\n",
            "cửa hàng_w: 161\n",
            "cửa sổ_w: 162\n",
            "cửa_w: 163\n",
            "cực kỳ_w: 164\n",
            "do đó_w: 165\n",
            "dài_w: 166\n",
            "dãy núi xa_w: 167\n",
            "dòng nước mát rượi_w: 168\n",
            "dòng nước trong vắt_w: 169\n",
            "dòng sông chảy_w: 170\n",
            "dòng sông dài rộng_w: 171\n",
            "dòng sông uốn lượn_w: 172\n",
            "dòng sông uốn_w: 173\n",
            "dòng đời trôi nhanh_w: 174\n",
            "dù sao_w: 175\n",
            "dù_w: 176\n",
            "dưới đây_w: 177\n",
            "dạy_w: 178\n",
            "dần dần_w: 179\n",
            "dẻo dai_w: 180\n",
            "dẻo_w: 181\n",
            "dễ dàng_w: 182\n",
            "dễ_w: 183\n",
            "dịch vụ_w: 184\n",
            "dừa_w: 185\n",
            "em_w: 186\n",
            "ghét_w: 187\n",
            "ghế đẩu_w: 188\n",
            "ghế_w: 189\n",
            "gia đình_w: 190\n",
            "giao tiếp_w: 191\n",
            "già_w: 192\n",
            "giá_w: 193\n",
            "giáo viên_w: 194\n",
            "giây_w: 195\n",
            "giã_w: 196\n",
            "giò_w: 197\n",
            "gió mát_w: 198\n",
            "gió mùa đông bắc_w: 199\n",
            "gió thổi mạnh_w: 200\n",
            "gió_w: 201\n",
            "giường_w: 202\n",
            "giấc mơ hạnh phúc_w: 203\n",
            "giấc mơ ngọt ngào_w: 204\n",
            "giấy_w: 205\n",
            "giọt sương ban mai_w: 206\n",
            "giọt sương mai_w: 207\n",
            "giờ_w: 208\n",
            "gà_w: 209\n",
            "gần_w: 210\n",
            "gầy_w: 211\n",
            "gặp_w: 212\n",
            "gỏi_w: 213\n",
            "hai_w: 214\n",
            "hay_w: 215\n",
            "hiếm khi_w: 216\n",
            "hiện tại_w: 217\n",
            "hoa cỏ xanh_w: 218\n",
            "hoa mai nở_w: 219\n",
            "hoa nở rực rỡ_w: 220\n",
            "hoa nở_w: 221\n",
            "hoa_w: 222\n",
            "hoàn toàn_w: 223\n",
            "hàng cây cổ thụ_w: 224\n",
            "hành trình_w: 225\n",
            "hát_w: 226\n",
            "hơi_w: 227\n",
            "hương hoa thoang thoảng_w: 228\n",
            "hương vị nồng nàn_w: 229\n",
            "hả_w: 230\n",
            "hấp dẫn_w: 231\n",
            "hấp_w: 232\n",
            "hẳn_w: 233\n",
            "hẹp_w: 234\n",
            "học sinh_w: 235\n",
            "học_w: 236\n",
            "hồng_w: 237\n",
            "hổ_w: 238\n",
            "hộp_w: 239\n",
            "kem_w: 240\n",
            "khi nào_w: 241\n",
            "khi_w: 242\n",
            "kho_w: 243\n",
            "khoai_w: 244\n",
            "khu phố sầm uất_w: 245\n",
            "khu phố_w: 246\n",
            "khu rừng bí ẩn_w: 247\n",
            "khá_w: 248\n",
            "khách sạn_w: 249\n",
            "khó khăn_w: 250\n",
            "khó_w: 251\n",
            "khóc_w: 252\n",
            "khô_w: 253\n",
            "không bao giờ_w: 254\n",
            "không_w: 255\n",
            "khỉ_w: 256\n",
            "khỏe_w: 257\n",
            "kia kia_w: 258\n",
            "kia này_w: 259\n",
            "kia đó_w: 260\n",
            "kia đấy_w: 261\n",
            "kia_w: 262\n",
            "kỳ hạn_w: 263\n",
            "kỳ nghỉ_w: 264\n",
            "kỳ thi_w: 265\n",
            "kỹ năng_w: 266\n",
            "liên quan_w: 267\n",
            "liên tục_w: 268\n",
            "luôn luôn_w: 269\n",
            "luộc_w: 270\n",
            "là_w: 271\n",
            "làm_w: 272\n",
            "làn da rám nắng_w: 273\n",
            "làn gió nhẹ nhàng_w: 274\n",
            "làn gió thoảng_w: 275\n",
            "làn khói bay_w: 276\n",
            "làn khói mong manh_w: 277\n",
            "làn khói mờ ảo bay_w: 278\n",
            "làn nước mát_w: 279\n",
            "làng quê thanh bình_w: 280\n",
            "làng quê yên bình_w: 281\n",
            "làng quê_w: 282\n",
            "làng xóm vui_w: 283\n",
            "lào_w: 284\n",
            "lá vàng rơi rụng_w: 285\n",
            "lên_w: 286\n",
            "lạnh_w: 287\n",
            "lớn_w: 288\n",
            "lợn_w: 289\n",
            "lửa_w: 290\n",
            "ma_w: 291\n",
            "mai_w: 292\n",
            "miến_w: 293\n",
            "mua_w: 294\n",
            "muống_w: 295\n",
            "muộn_w: 296\n",
            "mà vẫn_w: 297\n",
            "mà_w: 298\n",
            "mái hiên đỏ_w: 299\n",
            "mái nhà nhỏ_w: 300\n",
            "máy tính_w: 301\n",
            "máy ảnh_w: 302\n",
            "mây bay khắp trời_w: 303\n",
            "mèo_w: 304\n",
            "mì_w: 305\n",
            "môi trường_w: 306\n",
            "mùa hè nắng gắt_w: 307\n",
            "mùa hè rực rỡ_w: 308\n",
            "mùa xuân đâm chồi_w: 309\n",
            "mùa xuân ấm_w: 310\n",
            "mùa_w: 311\n",
            "mùi bánh mới nướng_w: 312\n",
            "mùi hương thoang thoảng_w: 313\n",
            "mùng_w: 314\n",
            "mơ_w: 315\n",
            "mưa rơi đều_w: 316\n",
            "mưa_w: 317\n",
            "mướp_w: 318\n",
            "mười_w: 319\n",
            "mạng lưới_w: 320\n",
            "mạnh_w: 321\n",
            "mận_w: 322\n",
            "mặc dù_w: 323\n",
            "mặn_w: 324\n",
            "mặt hồ lấp lánh_w: 325\n",
            "mặt trời đỏ_w: 326\n",
            "mặt trời_w: 327\n",
            "mẹ_w: 328\n",
            "mềm mại_w: 329\n",
            "mềm_w: 330\n",
            "mệt mỏi_w: 331\n",
            "mệt_w: 332\n",
            "mịn_w: 333\n",
            "mồng_w: 334\n",
            "mộng mơ_w: 335\n",
            "một câu chuyện vui_w: 336\n",
            "một góc phố nhỏ_w: 337\n",
            "một ngày đẹp trời_w: 338\n",
            "một đêm yên tĩnh_w: 339\n",
            "một_w: 340\n",
            "mới_w: 341\n",
            "mờ_w: 342\n",
            "mực_w: 343\n",
            "na_w: 344\n",
            "nai_w: 345\n",
            "nem_w: 346\n",
            "ngay lập tức_w: 347\n",
            "nghe_w: 348\n",
            "nghiêm túc_w: 349\n",
            "nghĩ_w: 350\n",
            "nghề nghiệp_w: 351\n",
            "ngoài ra_w: 352\n",
            "ngày hè ấm_w: 353\n",
            "ngày lễ_w: 354\n",
            "ngày mới bắt đầu_w: 355\n",
            "ngày_w: 356\n",
            "ngân hàng_w: 357\n",
            "ngô_w: 358\n",
            "ngôi chùa cổ kính_w: 359\n",
            "ngôi nhà nhỏ nhắn_w: 360\n",
            "ngôi trường thân yêu_w: 361\n",
            "người_w: 362\n",
            "ngẫu nhiên_w: 363\n",
            "ngắn_w: 364\n",
            "ngọn cỏ non xanh_w: 365\n",
            "ngọn núi cao vời vợi_w: 366\n",
            "ngọn núi phủ mây_w: 367\n",
            "ngọn núi phủ sương mù_w: 368\n",
            "ngọn đồi thoai thoải_w: 369\n",
            "ngọt_w: 370\n",
            "ngồi_w: 371\n",
            "ngủ_w: 372\n",
            "nhanh chóng_w: 373\n",
            "nhanh nhẹn_w: 374\n",
            "nhanh_w: 375\n",
            "nho_w: 376\n",
            "nhà cửa_w: 377\n",
            "nhà hàng_w: 378\n",
            "nhà_w: 379\n",
            "nhân viên_w: 380\n",
            "như khi_w: 381\n",
            "như thế nào_w: 382\n",
            "như vậy_w: 383\n",
            "như_w: 384\n",
            "nhưng vẫn_w: 385\n",
            "nhưng_w: 386\n",
            "nhảy_w: 387\n",
            "nhẵn_w: 388\n",
            "nhẹ_w: 389\n",
            "nhỏ_w: 390\n",
            "nhớ_w: 391\n",
            "những chiếc lá vàng_w: 392\n",
            "những ngôi sao sáng_w: 393\n",
            "này_w: 394\n",
            "nên rằng_w: 395\n",
            "nên_w: 396\n",
            "nói_w: 397\n",
            "núi đồi xa_w: 398\n",
            "núi_w: 399\n",
            "năm_w: 400\n",
            "nước uống_w: 401\n",
            "nước_w: 402\n",
            "nướng_w: 403\n",
            "nấu_w: 404\n",
            "nắng_w: 405\n",
            "nặng_w: 406\n",
            "nếu_w: 407\n",
            "nọ_w: 408\n",
            "nữa_w: 409\n",
            "phê_w: 410\n",
            "phòng khám_w: 411\n",
            "phút_w: 412\n",
            "phố_w: 413\n",
            "phở_w: 414\n",
            "qua_w: 415\n",
            "quay_w: 416\n",
            "quyển_w: 417\n",
            "quá khứ_w: 418\n",
            "quá trình_w: 419\n",
            "quá_w: 420\n",
            "quên_w: 421\n",
            "quýt_w: 422\n",
            "ra_w: 423\n",
            "rang_w: 424\n",
            "rau củ_w: 425\n",
            "rau_w: 426\n",
            "rán_w: 427\n",
            "rượu_w: 428\n",
            "rất_w: 429\n",
            "rắn chắc_w: 430\n",
            "rắn_w: 431\n",
            "rằng_w: 432\n",
            "rồi_w: 433\n",
            "rỗ_w: 434\n",
            "rộng_w: 435\n",
            "rực_w: 436\n",
            "sa_w: 437\n",
            "sai_w: 438\n",
            "sinh hoạt_w: 439\n",
            "sinh viên_w: 440\n",
            "sách báo_w: 441\n",
            "sách vở_w: 442\n",
            "sách_w: 443\n",
            "sáng sủa_w: 444\n",
            "sáng_w: 445\n",
            "sáu_w: 446\n",
            "sôi động_w: 447\n",
            "sông dài trôi mãi_w: 448\n",
            "sông dài_w: 449\n",
            "sông nước yên_w: 450\n",
            "sông_w: 451\n",
            "súp_w: 452\n",
            "sương mờ che_w: 453\n",
            "sạch_w: 454\n",
            "sạm_w: 455\n",
            "sần_w: 456\n",
            "sắc nét_w: 457\n",
            "sắn_w: 458\n",
            "sỏi_w: 459\n",
            "sống_w: 460\n",
            "sớm_w: 461\n",
            "sức khỏe_w: 462\n",
            "sức mạnh_w: 463\n",
            "sữa_w: 464\n",
            "sự kiện_w: 465\n",
            "thiếu_w: 466\n",
            "thu_w: 467\n",
            "thuốc_w: 468\n",
            "thành phố_w: 469\n",
            "tháng_w: 470\n",
            "thân thiện_w: 471\n",
            "thì_w: 472\n",
            "thú vị_w: 473\n",
            "thường xuyên_w: 474\n",
            "thường_w: 475\n",
            "thấp_w: 476\n",
            "thật_w: 477\n",
            "thế nào_w: 478\n",
            "thể thao_w: 479\n",
            "thỉnh thoảng_w: 480\n",
            "thịt_w: 481\n",
            "thời gian_w: 482\n",
            "thời tiết_w: 483\n",
            "thức ăn_w: 484\n",
            "thức_w: 485\n",
            "ti vi_w: 486\n",
            "tinh khiết_w: 487\n",
            "tinh tế_w: 488\n",
            "tivi_w: 489\n",
            "tiếng chim hót líu lo_w: 490\n",
            "tiếng chim hót_w: 491\n",
            "tiếng chim ríu rít_w: 492\n",
            "tiếng cười giòn tan_w: 493\n",
            "tiếng nước chảy róc rách_w: 494\n",
            "tiếng nước róc_w: 495\n",
            "tiếng ve ngân_w: 496\n",
            "tiện lợi_w: 497\n",
            "trong khi_w: 498\n",
            "trong_w: 499\n",
            "trà_w: 500\n",
            "trái cây thơm ngon_w: 501\n",
            "trái cây_w: 502\n",
            "trái ngọt chín_w: 503\n",
            "tráng lệ_w: 504\n",
            "trâu_w: 505\n",
            "trên đây_w: 506\n",
            "trăng non lên_w: 507\n",
            "trăng sáng_w: 508\n",
            "trơn_w: 509\n",
            "trường học_w: 510\n",
            "trường_w: 511\n",
            "trắng_w: 512\n",
            "trẻ_w: 513\n",
            "trời cao_w: 514\n",
            "trời mưa tầm tã_w: 515\n",
            "trời đông lạnh_w: 516\n",
            "trời_w: 517\n",
            "trứng_w: 518\n",
            "trừ khi_w: 519\n",
            "tuy nhiên_w: 520\n",
            "tuy vậy_w: 521\n",
            "tuyệt_w: 522\n",
            "tám_w: 523\n",
            "táo_w: 524\n",
            "tìm_w: 525\n",
            "tình bạn chân thành_w: 526\n",
            "tình bạn_w: 527\n",
            "tình trạng_w: 528\n",
            "tình yêu_w: 529\n",
            "tím_w: 530\n",
            "tôm_w: 531\n",
            "túy_w: 532\n",
            "tơi_w: 533\n",
            "tươi_w: 534\n",
            "tương lai_w: 535\n",
            "tại sao lại_w: 536\n",
            "tại sao_w: 537\n",
            "tại_w: 538\n",
            "tạm thời_w: 539\n",
            "tất nhiên_w: 540\n",
            "tối thiểu_w: 541\n",
            "tối đa_w: 542\n",
            "tối_w: 543\n",
            "tốt đẹp_w: 544\n",
            "tốt_w: 545\n",
            "tổng thể_w: 546\n",
            "tờ_w: 547\n",
            "tủ lạnh_w: 548\n",
            "tức thì_w: 549\n",
            "từ từ_w: 550\n",
            "từ_w: 551\n",
            "tự do_w: 552\n",
            "uống_w: 553\n",
            "viết_w: 554\n",
            "voi_w: 555\n",
            "vui tính_w: 556\n",
            "vui vẻ_w: 557\n",
            "vui_w: 558\n",
            "và_w: 559\n",
            "vàng_w: 560\n",
            "vào_w: 561\n",
            "vì thế_w: 562\n",
            "vì vậy_w: 563\n",
            "vì_w: 564\n",
            "vườn hoa khoe sắc_w: 565\n",
            "vườn nhà yên tĩnh_w: 566\n",
            "vườn rau xanh mướt_w: 567\n",
            "vầng trăng khuyết mờ_w: 568\n",
            "vậy nên_w: 569\n",
            "vậy_w: 570\n",
            "về_w: 571\n",
            "vịt_w: 572\n",
            "với_w: 573\n",
            "vở_w: 574\n",
            "vừa đủ_w: 575\n",
            "vừa_w: 576\n",
            "xa_w: 577\n",
            "xanh_w: 578\n",
            "xe hơi_w: 579\n",
            "xe máy_w: 580\n",
            "xe đạp_w: 581\n",
            "xe_w: 582\n",
            "xem_w: 583\n",
            "xoài_w: 584\n",
            "xuống_w: 585\n",
            "xào_w: 586\n",
            "xám_w: 587\n",
            "xấu xa_w: 588\n",
            "xấu_w: 589\n",
            "yêu_w: 590\n",
            "yếu_w: 591\n",
            "à_w: 592\n",
            "ánh chiều tà_w: 593\n",
            "ánh hoàng hôn đỏ_w: 594\n",
            "ánh mắt ngơ ngác_w: 595\n",
            "ánh mắt trìu mến_w: 596\n",
            "ánh nắng buổi sáng_w: 597\n",
            "ánh nắng chiếu_w: 598\n",
            "ánh sáng bình minh tỏa_w: 599\n",
            "ánh sáng dịu dàng_w: 600\n",
            "ánh sáng hồng_w: 601\n",
            "ánh trăng rơi_w: 602\n",
            "ánh trăng sáng tỏ_w: 603\n",
            "ánh đèn lấp lánh_w: 604\n",
            "ô tô_w: 605\n",
            "ông_w: 606\n",
            "ăn_w: 607\n",
            "đen_w: 608\n",
            "đi_w: 609\n",
            "điểm danh_w: 610\n",
            "điểm_w: 611\n",
            "điện thoại_w: 612\n",
            "đào_w: 613\n",
            "đâm_w: 614\n",
            "đây_w: 615\n",
            "đèn lồng_w: 616\n",
            "đèn_w: 617\n",
            "đêm hè êm_w: 618\n",
            "đêm trăng tĩnh mịch_w: 619\n",
            "đêm đông lạnh giá_w: 620\n",
            "đó kia_w: 621\n",
            "đó_w: 622\n",
            "đôi bàn tay ấm_w: 623\n",
            "đôi khi_w: 624\n",
            "đôi mắt sáng ngời_w: 625\n",
            "đúng lúc_w: 626\n",
            "đúng_w: 627\n",
            "đường phố rộn ràng_w: 628\n",
            "đường phố_w: 629\n",
            "đường_w: 630\n",
            "đất_w: 631\n",
            "đậu_w: 632\n",
            "đắng_w: 633\n",
            "đẳng cấp_w: 634\n",
            "đặc biệt_w: 635\n",
            "đẹp mắt_w: 636\n",
            "đẹp_w: 637\n",
            "đến_w: 638\n",
            "để mà_w: 639\n",
            "để_w: 640\n",
            "địa chỉ_w: 641\n",
            "đọc_w: 642\n",
            "đỏ_w: 643\n",
            "đồ chơi_w: 644\n",
            "đồi thông xanh_w: 645\n",
            "đồng hồ_w: 646\n",
            "độc đáo_w: 647\n",
            "đội bóng_w: 648\n",
            "đứng_w: 649\n",
            "ơi_w: 650\n",
            "ướt_w: 651\n",
            "ấm_w: 652\n",
            "ếch_w: 653\n",
            "ồ ò_w: 654\n",
            "ồ_w: 655\n",
            "ổi_w: 656\n",
            "ở đâu_w: 657\n",
            "ở_w: 658\n",
            "ừ_w: 659\n",
            "Training history plot saved to 'training_history.png'\n",
            "Saved preprocessing info to preprocessing_info.txt\n",
            "Training complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}